{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a1ebe75c-08a6-4b3c-9eb8-344dc9598aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import gp\n",
    "import operator\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.notebook import trange\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f049b724-830e-4644-8e10-b9f9b57c7b24",
   "metadata": {},
   "source": [
    "## Primitive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39a9136f-e70a-4c70-a512-9d3c837c0a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protectedDiv(left, right):\n",
    "    try:\n",
    "        return left / right\n",
    "    except ZeroDivisionError:\n",
    "        return 1\n",
    "\n",
    "pset = gp.PrimitiveSet(\"MAIN\", 1)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addPrimitive(protectedDiv, 2)\n",
    "pset.addPrimitive(math.cos, 1)\n",
    "\n",
    "pset.renameArguments(ARG0='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e614af-f902-4c39-8494-7476a04e9f0b",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b9970165-e9d1-493f-b56a-66c07d628049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_tree(pset, min_, max_):\n",
    "    expr = gp.genHalfAndHalf(pset, min_=min_, max_=max_)\n",
    "    tree = gp.PrimitiveTree(expr)\n",
    "    return tree\n",
    "\n",
    "def build_primitives_terminals_dict(pset):\n",
    "    prims = dict()\n",
    "    prims_funcs = list(pset.primitives.values())[0]\n",
    "    prims_names = [p.name for p in prims_funcs]\n",
    "    prims.update(zip(prims_names, prims_funcs))\n",
    "\n",
    "    # for arguments, add key = value = name to the dict\n",
    "    for arg in pset.arguments:\n",
    "        prims[str(arg)] = arg\n",
    "\n",
    "    return prims\n",
    "\n",
    "def tree_to_nodes_matrix(tree: gp.PrimitiveTree, pset: gp.PrimitiveSet, prims_names: list, n_nodes=0):\n",
    "    n_prims = pset.prims_count + len(pset.arguments)\n",
    "    if n_nodes == 0:\n",
    "        n_nodes = len(tree)\n",
    "    m = np.zeros((n_nodes, n_prims))\n",
    "\n",
    "    for i, prim in enumerate(tree):\n",
    "        prim_name = prim.name.replace('ARG0', 'x')\n",
    "        prim_idx = prims_names.index(prim_name)\n",
    "        m[i, prim_idx] = 1.\n",
    "    \n",
    "    return m\n",
    "\n",
    "def eval_fitness(tree, pset, points):\n",
    "    func = gp.compile(tree, pset)\n",
    "\n",
    "    sqerrors = ((func(x) - (x**2 + math.cos(x)))**2 for x in points)\n",
    "    return math.fsum(sqerrors) / len(points)\n",
    "\n",
    "def generate_dataset(n_samples, pset, min_, max_, points, prims_names):\n",
    "    n_prims = pset.prims_count + len(pset.arguments)\n",
    "    max_nodes = 2**(max_+1) - 1\n",
    "    X = np.zeros((n_samples, max_nodes*n_prims))\n",
    "    y = np.zeros((n_samples,1))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        fit = math.nan\n",
    "        while math.isnan(fit) or math.isinf(fit):\n",
    "            tree = generate_random_tree(pset, min_, max_)\n",
    "            m = tree_to_nodes_matrix(tree, pset, prims_names, max_nodes).ravel()\n",
    "            try:\n",
    "                fit = eval_fitness(tree, pset, points)\n",
    "            except:\n",
    "                fit = math.nan\n",
    "\n",
    "        X[i,:] = m        \n",
    "        y[i,:] = fit\n",
    "\n",
    "    return X, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b97c4d3-be8c-47e7-aa55-3f7388a9993e",
   "metadata": {},
   "source": [
    "## Generation of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5c67ec91-c720-41c8-804e-24de7a927563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub(add(mul(x, x), add(x, x)), protectedDiv(cos(x), cos(x)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = generate_random_tree(pset, min_=1, max_=3)\n",
    "print(tree)\n",
    "prims = build_primitives_terminals_dict(pset)\n",
    "tree_to_nodes_matrix(tree, pset, list(prims.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3f5251f4-9fb4-4db7-976b-2c18c4f380bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3053788965164381"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = np.arange(0.,1.1,0.1)\n",
    "print(points)\n",
    "eval_fitness(tree, pset, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "93b152ea-57ba-4813-9f78-865eb14f7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "import torch\n",
    "device = \"cpu\"\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e8f59060-6001-4a0d-afb0-2071ea14dd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41010/2793393697.py:3: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return left / right\n",
      "/tmp/ipykernel_41010/2793393697.py:3: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return left / right\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "min_ = 1\n",
    "max_ = 3\n",
    "max_nodes = 2**(max_+1) - 1\n",
    "n_prims = pset.prims_count + len(pset.arguments)\n",
    "n_samples = 1000\n",
    "X, y = generate_dataset(n_samples, pset, min_, max_, points, list(prims.keys()))\n",
    "y_normalized = (y - np.mean(y))/np.std(y)\n",
    "frac = 0.8\n",
    "\n",
    "generator = torch.Generator(device=device)\n",
    "\n",
    "X_train, X_valid = random_split(X, [frac, 1-frac], generator=generator)\n",
    "y_train, y_valid = random_split(y_normalized, [frac, 1-frac], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "ba21cbe1-d707-4cdc-9e72-d0b240b05e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None, target_transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return X[idx,:], y[idx,:]\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "valid_dataset = CustomDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "462e8ff9-a61a-4702-be4e-e4994d94edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(max_nodes*n_prims, 2*max_nodes*n_prims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*max_nodes*n_prims, 2*max_nodes*n_prims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*max_nodes*n_prims, 2*max_nodes*n_prims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*max_nodes*n_prims, max_nodes*n_prims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(max_nodes*n_prims, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "29427a66-f5b7-4b61-9d53-a82495e685b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "\n",
    "    ave_train_loss = 0.\n",
    "    num_batches = len(dataloader)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # print(X.shape)\n",
    "        # print(pred.shape)\n",
    "        # print(y.shape)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        ave_train_loss += loss.item()/num_batches\n",
    "\n",
    "    return ave_train_loss\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    # model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c6892c6f-c0cd-4d24-90ef-0caa3b6b8fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a5a465cd144f5e92d7e8556fec7ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1000 [00:00<?, ?epochs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[299], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m pbar \u001b[38;5;241m=\u001b[39m trange(epochs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m---> 16\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     test_loss \u001b[38;5;241m=\u001b[39m test_loop(valid_dataloader, model, loss_fn)\n\u001b[1;32m     18\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix(train_loss\u001b[38;5;241m=\u001b[39mtrain_loss, test_loss\u001b[38;5;241m=\u001b[39mtest_loss)\n",
      "Cell \u001b[0;32mIn[298], line 15\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(X.shape)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(pred.shape)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# print(y.shape)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 15\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m ave_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39mnum_batches\n",
      "File \u001b[0;32m~/mambaforge/envs/alpine/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/alpine/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/mambaforge/envs/alpine/lib/python3.11/site-packages/torch/optim/adam.py:138\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;129m@_use_grad_for_differentiable\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Performs a single optimization step.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m            and returns the loss.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_graph_capture_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/alpine/lib/python3.11/site-packages/torch/optim/optimizer.py:321\u001b[0m, in \u001b[0;36mOptimizer._cuda_graph_capture_health_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_graph_capture_health_check\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# Note [torch.compile x capturable]\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_built() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 321\u001b[0m         capturing \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_current_stream_capturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m capturing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups):\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting CUDA graph capture of step() for an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    325\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    326\u001b[0m                                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but param_groups\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m capturable is False.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/alpine/lib/python3.11/site-packages/torch/cuda/graphs.py:32\u001b[0m, in \u001b[0;36mis_current_stream_capturing\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_current_stream_capturing\u001b[39m():\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Returns True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cuda_isCurrentStreamCapturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "learning_rate = 1e-4\n",
    "batch_size = 64\n",
    "epochs = 1000\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = None, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "model.train()\n",
    "pbar = trange(epochs, desc=\"Training\", unit=\"epochs\")\n",
    "for i in pbar:\n",
    "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loss = test_loop(valid_dataloader, model, loss_fn)\n",
    "    pbar.set_postfix(train_loss=train_loss, test_loss=test_loss)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "4e3f8d54-2281-4794-a8b9-bc64fdac0313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00010863952909585112"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.zeros((max_nodes, n_prims))\n",
    "test[:6,:] = np.array([[1,0,0,0,0,0], [0,0,1,0,0,0], [0,0,0,0,0,1], [0,0,0,0,0,1], [0,0,0,0,1,0], [0,0,0,0,0,1]])\n",
    "test_tensor = torch.from_numpy(test.flatten())\n",
    "pred = model(test_tensor)\n",
    "pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "b265cdad-3fc2-4d3f-ab9a-801cfd21e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    sm = torch.nn.Softmax(dim=1)\n",
    "    with torch.no_grad():\n",
    "        x_reshaped = torch.reshape(x, (max_nodes, n_prims))\n",
    "    return sm(x_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "7910f330-e637-4c17-bcc7-3d47d739ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_tree(x0: np.array, learning_rate, max_iter):\n",
    "    x0 = torch.tensor(x0, requires_grad = True)\n",
    "    optimizer_tree = torch.optim.Adam([x0], lr = learning_rate)\n",
    "    #sm = torch.nn.Softmax(dim=1)\n",
    "    pbar = trange(max_iter, desc=\"Best tree search\", unit=\"iters\")\n",
    "    for i in pbar:\n",
    "        pred = model(x0)\n",
    "        x0_reshaped = torch.reshape(x0, (max_nodes, n_prims))\n",
    "        penalty = 10*(torch.norm(torch.ones(x0_reshaped.shape[0])-torch.sum(x0_reshaped, dim=1)))**2\n",
    "        obj = pred + penalty\n",
    "        obj.backward()\n",
    "        optimizer_tree.step()\n",
    "        #optimizer_tree.zero_grad()\n",
    "        #with torch.no_grad():\n",
    "           \n",
    "        #    x0 = softmax(x0_reshaped).flatten().requires_grad_()\n",
    "        #    print(x0)\n",
    "        pbar.set_postfix(objective=pred.item())\n",
    "        # print(softmax(x0))\n",
    "        sleep(0.001)\n",
    "    return x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "5e38260a-d5c4-4de0-b126-5f6e6880e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add(x, x)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e636cdee5bd047278f49bbae83db858d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Best tree search:   0%|          | 0/10000 [00:00<?, ?iters/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree = generate_random_tree(pset, min_=1, max_=3)\n",
    "print(tree)\n",
    "x0 = tree_to_nodes_matrix(tree, pset, list(prims.keys()), n_nodes = max_nodes)\n",
    "#x0 = test_tensor\n",
    "x = optimize_tree(x0.ravel(), 1e-3, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "1793ea46-01f6-421d-a581-2c81b4f1f960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2458, 0.0265, 0.0445, 0.2548, 0.3849, 0.0436],\n",
       "        [0.0178, 0.3847, 0.1478, 0.1370, 0.1780, 0.1346],\n",
       "        [0.2579, 0.2150, 0.1386, 0.0505, 0.1401, 0.1979],\n",
       "        [0.1430, 0.1599, 0.1501, 0.1848, 0.1324, 0.2298],\n",
       "        [0.5548, 0.0416, 0.0551, 0.1126, 0.1499, 0.0860],\n",
       "        [0.1998, 0.1635, 0.0966, 0.1339, 0.2411, 0.1651],\n",
       "        [0.2528, 0.1905, 0.1358, 0.0808, 0.2254, 0.1146],\n",
       "        [0.1474, 0.2582, 0.2003, 0.0751, 0.2111, 0.1079],\n",
       "        [0.1698, 0.2736, 0.1480, 0.1941, 0.1487, 0.0657],\n",
       "        [0.2217, 0.0866, 0.1368, 0.2094, 0.1608, 0.1847],\n",
       "        [0.0810, 0.3191, 0.1058, 0.1608, 0.1960, 0.1373],\n",
       "        [0.1732, 0.2054, 0.0686, 0.1179, 0.1622, 0.2727],\n",
       "        [0.1528, 0.1970, 0.1388, 0.1883, 0.0886, 0.2345],\n",
       "        [0.1740, 0.1740, 0.1740, 0.1740, 0.1740, 0.1302],\n",
       "        [0.1723, 0.1723, 0.1723, 0.1723, 0.1723, 0.1385]])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = torch.nn.Softmax(dim=1)\n",
    "with torch.no_grad():\n",
    "    x_reshaped = torch.reshape(x, (max_nodes, n_prims))\n",
    "    x = sm(x_reshaped)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "88672cac-f4cf-4010-9943-1e448f3a02f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['add', 'sub', 'mul', 'protectedDiv', 'cos', 'x']\n"
     ]
    }
   ],
   "source": [
    "print(list(prims.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae791fb6-7422-4a16-a75f-41ad9f2faad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c9d7de-f58b-4567-b077-30d8da09782b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
