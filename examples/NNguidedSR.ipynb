{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ebe75c-08a6-4b3c-9eb8-344dc9598aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import gp\n",
    "import operator\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f049b724-830e-4644-8e10-b9f9b57c7b24",
   "metadata": {},
   "source": [
    "## Primitive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a9136f-e70a-4c70-a512-9d3c837c0a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protectedDiv(left, right):\n",
    "    try:\n",
    "        return left / right\n",
    "    except ZeroDivisionError:\n",
    "        return 1\n",
    "\n",
    "pset = gp.PrimitiveSet(\"MAIN\", 1)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addPrimitive(protectedDiv, 2)\n",
    "pset.addPrimitive(math.cos, 1)\n",
    "\n",
    "pset.renameArguments(ARG0='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e614af-f902-4c39-8494-7476a04e9f0b",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9970165-e9d1-493f-b56a-66c07d628049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_tree(pset, min_, max_):\n",
    "    expr = gp.genHalfAndHalf(pset, min_=min_, max_=max_)\n",
    "    tree = gp.PrimitiveTree(expr)\n",
    "    return tree\n",
    "\n",
    "def build_primitives_terminals_dict(pset):\n",
    "    prims = dict()\n",
    "    prims_funcs = list(pset.primitives.values())[0]\n",
    "    prims_names = [p.name for p in prims_funcs]\n",
    "    prims.update(zip(prims_names, prims_funcs))\n",
    "\n",
    "    # for arguments, add key = value = name to the dict\n",
    "    for arg in pset.arguments:\n",
    "        prims[str(arg)] = arg\n",
    "\n",
    "    return prims\n",
    "\n",
    "def tree_to_nodes_matrix(tree: gp.PrimitiveTree, pset: gp.PrimitiveSet, prims_names: list, n_nodes=0):\n",
    "    n_prims = pset.prims_count + len(pset.arguments)\n",
    "    if n_nodes == 0:\n",
    "        n_nodes = len(tree)\n",
    "    m = np.zeros((n_nodes, n_prims))\n",
    "\n",
    "    for i, prim in enumerate(tree):\n",
    "        prim_name = prim.name.replace('ARG0', 'x')\n",
    "        prim_idx = prims_names.index(prim_name)\n",
    "        m[i, prim_idx] = 1.\n",
    "    \n",
    "    return m\n",
    "\n",
    "def eval_fitness(tree, pset, points):\n",
    "    func = gp.compile(tree, pset)\n",
    "\n",
    "    sqerrors = ((func(x) - (x**2 + math.cos(x)))**2 for x in points)\n",
    "    return math.fsum(sqerrors) / len(points)\n",
    "\n",
    "def generate_dataset(n_samples, pset, min_, max_, points, prims_names):\n",
    "    n_prims = pset.prims_count + len(pset.arguments)\n",
    "    max_nodes = 2**(max_+1) - 1\n",
    "    X = np.zeros((n_samples, max_nodes*n_prims))\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        fit = math.nan\n",
    "        while math.isnan(fit) or math.isinf(fit):\n",
    "            tree = generate_random_tree(pset, min_, max_)\n",
    "            m = tree_to_nodes_matrix(tree, pset, prims_names, max_nodes).ravel()\n",
    "            try:\n",
    "                fit = eval_fitness(tree, pset, points)\n",
    "            except:\n",
    "                fit = math.nan\n",
    "\n",
    "        X[i,:] = m        \n",
    "        y[i,:] = fit\n",
    "\n",
    "    return X, y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b97c4d3-be8c-47e7-aa55-3f7388a9993e",
   "metadata": {},
   "source": [
    "## Generation of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c67ec91-c720-41c8-804e-24de7a927563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul(protectedDiv(x, x), cos(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = generate_random_tree(pset, min_=1, max_=3)\n",
    "print(tree)\n",
    "prims = build_primitives_terminals_dict(pset)\n",
    "tree_to_nodes_matrix(tree, pset, list(prims.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f5251f4-9fb4-4db7-976b-2c18c4f380bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/8nyd9hnd0n9dtx4st6g2d5zj_v2dvq/T/ipykernel_54972/2793393697.py:3: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return left / right\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = np.arange(0.,1.1,0.1)\n",
    "print(points)\n",
    "eval_fitness(tree, pset, points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93b152ea-57ba-4813-9f78-865eb14f7bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e8f59060-6001-4a0d-afb0-2071ea14dd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/8nyd9hnd0n9dtx4st6g2d5zj_v2dvq/T/ipykernel_54972/2793393697.py:3: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return left / right\n",
      "/var/folders/6x/8nyd9hnd0n9dtx4st6g2d5zj_v2dvq/T/ipykernel_54972/2793393697.py:3: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return left / right\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.set_default_dtype(torch.float64)\n",
    "min_ = 1\n",
    "max_ = 3\n",
    "max_nodes = 2**(max_+1) - 1\n",
    "n_prims = pset.prims_count + len(pset.arguments)\n",
    "n_samples = 1000\n",
    "X, y = generate_dataset(n_samples, pset, min_, max_, points, list(prims.keys()))\n",
    "y_normalized = (y - np.mean(y))/np.std(y)\n",
    "frac = 0.8\n",
    "X_train, X_valid = random_split(X, [frac, 1-frac])\n",
    "y_train, y_valid = random_split(y_normalized, [frac, 1-frac])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ba21cbe1-d707-4cdc-9e72-d0b240b05e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None, target_transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return X[idx,:], y[idx, 0]\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "valid_dataset = CustomDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "462e8ff9-a61a-4702-be4e-e4994d94edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(max_nodes*n_prims, 2*max_nodes*n_prims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*max_nodes*n_prims, 2*max_nodes*n_prims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*max_nodes*n_prims, 2*max_nodes*n_prims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*max_nodes*n_prims, max_nodes*n_prims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(max_nodes*n_prims, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "29427a66-f5b7-4b61-9d53-a82495e685b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # if batch % 100 == 0:\n",
    "        #    loss, current = loss.item(), (batch + 1) * len(X)\n",
    "        #    print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c6892c6f-c0cd-4d24-90ef-0caa3b6b8fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.368981 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.374681 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.606294 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 1.083269 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 1.600060 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 2.302049 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 2.926142 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 3.352274 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 2.962078 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 1.299532 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.727187 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.465645 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.622650 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.449646 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.380784 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.333329 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.482341 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.580183 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.272942 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.224105 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.320811 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.221017 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.177659 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.165074 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.254177 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.150277 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.138581 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.126061 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.129365 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.088431 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.093115 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.083285 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.110208 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.091823 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.060358 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.075880 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.057889 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.065837 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.062999 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.045259 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.052450 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.050159 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.061585 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.036033 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.046172 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.035011 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.050719 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.040677 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.025794 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.035035 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.024327 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.063274 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.030849 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.022867 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.021295 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.018026 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.022755 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.024553 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.023514 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.015350 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.018721 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.013765 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.012726 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.017316 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.009400 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.010921 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.019028 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.008592 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.012009 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.013257 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.005408 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.012960 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004785 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.011127 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.009194 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.009823 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.007302 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004731 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.048935 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.009313 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002873 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.012732 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.009160 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.007644 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.008478 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002797 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.009379 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003457 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.010928 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003461 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003430 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003067 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.005874 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.042964 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.008121 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001749 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004079 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.009068 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004422 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.010501 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003411 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.008089 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001877 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.007012 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004933 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004510 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.009377 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003484 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002691 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.010177 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001956 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002729 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.009448 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002020 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001553 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.006633 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001729 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002121 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.009246 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003735 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001832 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.007689 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004509 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001039 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.005639 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.005400 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002198 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002312 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.006636 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002771 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004598 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001443 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004720 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003164 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000833 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001593 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004809 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.033488 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.020356 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.008365 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004574 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002571 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001763 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001718 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.006922 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004206 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004640 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004520 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001746 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001477 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002113 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.036561 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.009402 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.010019 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002116 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001516 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000878 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003314 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.007051 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002698 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000776 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001679 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001954 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003667 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003297 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001266 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002823 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002473 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.006682 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.006486 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001816 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004743 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003307 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001890 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001557 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003915 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.006550 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.006374 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002036 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000658 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000887 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003095 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004424 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004036 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001983 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002929 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.005328 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.006290 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003113 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.010041 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001805 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002596 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.006601 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001734 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000965 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001232 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002377 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004833 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001970 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003088 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002679 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002698 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002436 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004279 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002347 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002502 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001358 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002779 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002972 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.013040 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004899 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.009811 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000882 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001077 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000679 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001808 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002156 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004447 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001769 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000758 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001633 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002551 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002764 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001145 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001538 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000941 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001414 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001298 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000967 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002504 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002873 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.006631 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.010051 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004121 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002395 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.005265 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000835 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000847 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001719 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002744 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001766 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001857 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004812 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001965 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000384 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000337 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003397 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003291 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004021 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003252 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002223 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002081 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001562 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001507 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001723 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004238 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003204 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001123 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000696 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001435 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.005533 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002119 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000898 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001441 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004278 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.006778 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003537 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000704 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000697 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001012 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001230 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001767 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003656 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001898 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000921 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000610 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000523 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004657 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002658 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.004009 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001329 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000589 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001228 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003753 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002398 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.011250 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000794 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000721 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000924 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002632 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001412 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001333 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000678 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000683 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000743 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002015 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001964 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000682 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001077 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002596 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002071 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001583 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000997 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002093 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001194 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001167 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001274 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000812 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000849 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001670 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003992 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002267 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000921 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000936 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001211 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001239 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001571 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001614 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001988 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001083 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.010862 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000971 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001337 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002281 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001302 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001344 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000985 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001481 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003557 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001667 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000712 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000766 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001864 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002896 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002438 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000935 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000650 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001774 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001622 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001202 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001502 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001656 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001151 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.008680 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001299 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001067 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002648 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000915 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000767 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001023 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000775 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002285 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002840 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000673 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001150 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001028 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001099 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002050 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002310 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001179 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001047 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001925 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003593 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002422 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001484 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000951 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000744 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001048 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001335 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001642 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003431 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001605 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000290 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000526 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000858 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001057 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001213 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002546 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001520 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.006875 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001308 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001046 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001871 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001082 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001748 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000682 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000751 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000950 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000751 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002069 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001001 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001579 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002071 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000636 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000287 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000904 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001858 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001522 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001521 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001480 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000974 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000877 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000980 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000712 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000925 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001373 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000828 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001542 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001229 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001975 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003292 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002311 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001558 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000961 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000862 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000857 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000881 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001617 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002015 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000877 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001962 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001157 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000401 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000612 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002161 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002690 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001195 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001474 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001103 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001629 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001196 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001304 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001123 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001251 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001112 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001827 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001461 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001379 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000820 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001326 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000967 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001003 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001111 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001485 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001086 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001137 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000664 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000778 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001025 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001612 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000875 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000518 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000602 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001528 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001336 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000990 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001019 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000957 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000997 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001133 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001848 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001098 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001054 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000577 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000706 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001200 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001251 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000616 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000703 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000698 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000969 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000858 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000566 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002224 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001449 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001151 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000833 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001140 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000664 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000993 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001235 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001135 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000425 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000515 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000728 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001508 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000576 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000659 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000980 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000997 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000558 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000919 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002455 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000609 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000493 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001250 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001607 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001588 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001023 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000697 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001116 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001277 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.003448 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000728 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001367 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000990 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001169 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001099 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001135 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000607 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000708 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001076 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001467 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000770 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001341 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001327 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001053 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000672 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001200 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001195 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001050 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000737 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001408 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000823 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000780 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000677 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000948 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000782 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000791 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000872 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001058 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000661 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000653 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001570 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001273 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001003 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000798 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000981 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000479 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000494 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001149 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001821 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000698 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000355 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000698 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001288 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000612 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000572 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001724 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001056 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000995 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000852 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000665 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000481 \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000866 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001088 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000987 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000603 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000337 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000430 \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001643 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001658 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000276 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000203 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000382 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000712 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001262 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001338 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000951 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000512 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000524 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001289 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000660 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000395 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001208 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001186 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000983 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000812 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000725 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000539 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000933 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001077 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000813 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000673 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000870 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000856 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000906 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000602 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000591 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001031 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001786 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000952 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000775 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000517 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000583 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000772 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001215 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000936 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000634 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000475 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000873 \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000628 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000695 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001540 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001565 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000970 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000831 \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000646 \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000682 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001019 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001170 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000736 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000714 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000748 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000760 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000552 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000559 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001252 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001149 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000504 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000332 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000624 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001509 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001014 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000289 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000469 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000455 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000411 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000948 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001393 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001021 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000864 \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000520 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000600 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000443 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000486 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000910 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001317 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000526 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000547 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000681 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000584 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000611 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000888 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000519 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000559 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001885 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.002401 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001011 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000330 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001020 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001854 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000986 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000489 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000398 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000479 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000849 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000678 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000572 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000584 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001685 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001384 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000468 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000407 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000385 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000530 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000897 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000984 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000736 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000686 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000403 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000541 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001327 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001404 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000570 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000276 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000362 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000585 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001227 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001232 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000529 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000449 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000395 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000589 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001110 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000860 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000853 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000632 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000715 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000703 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000643 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000714 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000726 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000893 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000603 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000560 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000578 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000842 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000752 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000638 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000688 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000707 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000643 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000409 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000693 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001261 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001428 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000943 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000503 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000367 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000555 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000807 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000687 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000851 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000324 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001631 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001256 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000802 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000737 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000421 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000494 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000813 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000412 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001189 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001355 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000772 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000806 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000750 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000333 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001020 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001504 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000407 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000281 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000635 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000884 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000715 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000892 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000966 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000816 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000675 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000598 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000707 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000913 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000771 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000678 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000626 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000575 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000439 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001028 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000848 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000949 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000878 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000525 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000851 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000533 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000494 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000438 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000430 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000448 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000551 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000736 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000736 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000587 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000543 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000867 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001044 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000822 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000467 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000208 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000272 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000534 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000851 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000888 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000496 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001262 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000624 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000328 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000459 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000451 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000497 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000458 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000769 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000536 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000273 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000600 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001490 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000570 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000575 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000819 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000600 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000566 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000605 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000701 \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000619 \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000559 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000477 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000504 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000683 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000647 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000798 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000649 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000743 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000606 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000490 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000359 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000804 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000926 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000583 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000430 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000896 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001048 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000964 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000351 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000271 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000629 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000737 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000531 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000504 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000407 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000537 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000465 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000448 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000333 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000260 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000674 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000599 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000901 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000766 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000431 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000616 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001394 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000399 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000516 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000494 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001069 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000703 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000608 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000532 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000417 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000399 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000414 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000755 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000586 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000753 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000722 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000736 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000620 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000406 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000581 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000555 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000484 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000759 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000571 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000534 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000604 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000619 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000538 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000495 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000563 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000467 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000526 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000510 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000455 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001094 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000751 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000505 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000462 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000487 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000316 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000264 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000660 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000727 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000546 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000532 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000368 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000523 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000781 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000521 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000550 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001179 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000886 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000472 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000330 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000274 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000447 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001145 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000713 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000384 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000625 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001195 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000980 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000584 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000554 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000588 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000700 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000524 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000434 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000301 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000559 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000477 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000508 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000709 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000493 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000558 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000380 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000371 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000272 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000419 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000645 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000705 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001097 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000627 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000624 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000450 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000521 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000619 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000595 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000433 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000298 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000337 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000449 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000784 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000349 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000415 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000247 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000347 \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000776 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000522 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000741 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000793 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000366 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000450 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000358 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000329 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000417 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000523 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000357 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000465 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000291 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000823 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000781 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000229 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000296 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000268 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000315 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000342 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000541 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000533 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000264 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000328 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000531 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000650 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000406 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000205 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000342 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000483 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000401 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000366 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000321 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000417 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000387 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000283 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000289 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000353 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000446 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000334 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000455 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000611 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000565 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000591 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000502 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001049 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.001221 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000520 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000280 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000454 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000865 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000288 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000481 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000538 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000571 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000374 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000305 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000233 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000681 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000692 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000553 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000794 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000678 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000283 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000444 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000297 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000313 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000311 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000278 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000523 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000379 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000403 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000381 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "Test Error: Avg loss: 0.000298 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "learning_rate = 1e-4\n",
    "batch_size = 1\n",
    "epochs = 1000\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = None)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(valid_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4e3f8d54-2281-4794-a8b9-bc64fdac0313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0022937242056880885"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.zeros((max_nodes, n_prims))\n",
    "test[:6,:] = np.array([[1,0,0,0,0,0], [0,0,1,0,0,0], [0,0,0,0,0,1], [0,0,0,0,0,1], [0,0,0,0,1,0], [0,0,0,0,0,1]])\n",
    "test_tensor = torch.from_numpy(test.flatten())\n",
    "pred = model(test_tensor)\n",
    "pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b265cdad-3fc2-4d3f-ab9a-801cfd21e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    sm = torch.nn.Softmax(dim=1)\n",
    "    with torch.no_grad():\n",
    "        x_reshaped = torch.reshape(x, (max_nodes, n_prims))\n",
    "    return sm(x_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7910f330-e637-4c17-bcc7-3d47d739ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_tree(x0: np.array, learning_rate, max_iter):\n",
    "    x0 = torch.tensor(x0, requires_grad = True)\n",
    "    optimizer_tree = torch.optim.Adam([x0], lr = learning_rate)\n",
    "    #sm = torch.nn.Softmax(dim=1)\n",
    "    for i in range(max_iter):\n",
    "        pred = model(x0)\n",
    "        pred.backward()\n",
    "        optimizer_tree.step()\n",
    "        optimizer_tree.zero_grad()\n",
    "        #with torch.no_grad():\n",
    "        #    x0_reshaped = torch.reshape(x0, (max_nodes, n_prims))\n",
    "        #    x0 = sm(x0_reshaped).flatten().requires_grad_()\n",
    "        print(pred.item())\n",
    "        # print(softmax(x0))\n",
    "    return x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5e38260a-d5c4-4de0-b126-5f6e6880e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul(protectedDiv(sub(x, x), sub(x, x)), protectedDiv(mul(x, x), protectedDiv(x, x)))\n",
      "0.743423375185207\n",
      "0.7115612591726094\n",
      "0.6779824539549805\n",
      "0.6405427254642633\n",
      "0.6082357965849474\n",
      "0.6371015366847466\n",
      "0.6323480415767231\n",
      "0.6033591164087836\n",
      "0.5877860267980892\n",
      "0.5899527344765011\n",
      "0.590751602655142\n",
      "0.5894782682931514\n",
      "0.5864207322338725\n",
      "0.5802908937429574\n",
      "0.5721595295089139\n",
      "0.563152281298401\n",
      "0.5543309214101926\n",
      "0.545924985942168\n",
      "0.5454260241105295\n",
      "0.5439196620655649\n",
      "0.5402156376333195\n",
      "0.5342328464892746\n",
      "0.526318508294126\n",
      "0.5183369331941824\n",
      "0.5171532075745663\n",
      "0.5158225312860034\n",
      "0.5127345753500063\n",
      "0.5074870546502207\n",
      "0.5007357090898481\n",
      "0.4942823762765209\n",
      "0.49252736494968374\n",
      "0.4902502694909402\n",
      "0.48627357574638047\n",
      "0.4817789423182731\n",
      "0.47661945837543646\n",
      "0.4733166067438988\n",
      "0.47165286086348873\n",
      "0.46864042850429255\n",
      "0.46416213621703595\n",
      "0.45989178858266627\n",
      "0.4584086573131883\n",
      "0.45590483580978985\n",
      "0.4522567992884226\n",
      "0.44839136375159633\n",
      "0.4449892350328953\n",
      "0.44322297904693525\n",
      "0.4405474169137667\n",
      "0.43680391667706053\n",
      "0.43335653493192644\n",
      "0.43102858501661495\n",
      "0.42833682813184587\n",
      "0.4253119062342658\n",
      "0.4221196590628267\n",
      "0.4196061913989267\n",
      "0.416927728051196\n",
      "0.4145291847060775\n",
      "0.41226391681447594\n",
      "0.40997387598057705\n",
      "0.407793630840214\n",
      "0.4056036696840628\n",
      "0.4033324668858062\n",
      "0.4009841813640672\n",
      "0.3986113040994848\n",
      "0.3960541521761993\n",
      "0.3943286928504224\n",
      "0.3916431454809457\n",
      "0.3891637706047597\n",
      "0.3871061773674298\n",
      "0.3849765219376765\n",
      "0.38273114429711885\n",
      "0.38037952490671806\n",
      "0.37808844384724527\n",
      "0.3757852450486168\n",
      "0.37347852477502136\n",
      "0.372015864569334\n",
      "0.3698981373975287\n",
      "0.36735561560424607\n",
      "0.365489614087224\n",
      "0.3635695901915419\n",
      "0.36159967736785226\n",
      "0.3595836318449314\n",
      "0.35752486726294813\n",
      "0.3554306594796853\n",
      "0.35331917750855124\n",
      "0.35117899316000284\n",
      "0.3490795865593995\n",
      "0.3471836965494343\n",
      "0.34510753127762184\n",
      "0.3432114667242995\n",
      "0.3412751244470826\n",
      "0.3393169164497934\n",
      "0.3373430853993495\n",
      "0.3353462835261211\n",
      "0.333323795607046\n",
      "0.3308090999350618\n",
      "0.3281971015303878\n",
      "0.3254643530634973\n",
      "0.32324304756734945\n",
      "0.3207054429819365\n",
      "0.3177005333320505\n",
      "0.3152142281797604\n",
      "0.3128380178766135\n",
      "0.3103849354913831\n",
      "0.30775673754971733\n",
      "0.30615983177746425\n",
      "0.3039357050526487\n",
      "0.3011042519801719\n",
      "0.2988156370588593\n",
      "0.2968400533627915\n",
      "0.29468756329229046\n",
      "0.2923349160717776\n",
      "0.28987986735476673\n",
      "0.2873972377610329\n",
      "0.28504522110250646\n",
      "0.2827543571563205\n",
      "0.280675913050091\n",
      "0.27864886747731427\n",
      "0.27655768230497596\n",
      "0.27440784054104655\n",
      "0.2722043023429217\n",
      "0.26998242899026137\n",
      "0.26794467167567226\n",
      "0.2658910807959629\n",
      "0.26383390686714586\n",
      "0.2617595884231018\n",
      "0.2597886227105303\n",
      "0.2578835689388699\n",
      "0.25605965893319166\n",
      "0.25404167186487864\n",
      "0.2521804251279737\n",
      "0.25033760702985414\n",
      "0.2483529145647314\n",
      "0.24642642382173913\n",
      "0.24457256746131703\n",
      "0.24273989220549053\n",
      "0.24084637489926702\n",
      "0.23898365961832696\n",
      "0.2371217577171575\n",
      "0.23526020097091987\n",
      "0.23339856750246718\n",
      "0.23153647738311167\n",
      "0.229733364225835\n",
      "0.22756196290143813\n",
      "0.2251110807542028\n",
      "0.22255602785968415\n",
      "0.21990407378428223\n",
      "0.2172435713400132\n",
      "0.2146137305576054\n",
      "0.21198730944514804\n",
      "0.20933975041269892\n",
      "0.20682346766193888\n",
      "0.2046171634978023\n",
      "0.20259123934430118\n",
      "0.20066096064095124\n",
      "0.1987445571340714\n",
      "0.19688969067928963\n",
      "0.19507613494309117\n",
      "0.19329195210474132\n",
      "0.19151475740172752\n",
      "0.18973992005226503\n",
      "0.18797918398412888\n",
      "0.18626410230677504\n",
      "0.18462539770850267\n",
      "0.18299636406660247\n",
      "0.18137402360829433\n",
      "0.1797590242801118\n",
      "0.17814923754701834\n",
      "0.17654385481947615\n",
      "0.17502074854688296\n",
      "0.17350891609012398\n",
      "0.17201029238203375\n",
      "0.1705154678107266\n",
      "0.16902694731188728\n",
      "0.16839836634509217\n",
      "0.16786807255067882\n",
      "0.16733333066298817\n",
      "0.16681408552105625\n",
      "0.1662663400902037\n",
      "0.16572676813648668\n",
      "0.16518636458301655\n",
      "0.1646451093790307\n",
      "0.16410298287140562\n",
      "0.1635599659660944\n",
      "0.16301808280803193\n",
      "0.16247940150326376\n",
      "0.1619400093690393\n",
      "0.16139986794838668\n",
      "0.16085894195907646\n",
      "0.16031719907615571\n",
      "0.1597864064183892\n",
      "0.15924790557104615\n",
      "0.15870493931043103\n",
      "0.15822577827772677\n",
      "0.15775531297274392\n",
      "0.15728752428986653\n",
      "0.15682205345155054\n",
      "0.15635964031745359\n",
      "0.1558992960258922\n",
      "0.15544040304517814\n",
      "0.15498283100599305\n",
      "0.15452635506167786\n",
      "0.15407077246658402\n",
      "0.15361590042809936\n",
      "0.15316420695590172\n",
      "0.15271417773416912\n",
      "0.1522656604741752\n",
      "0.1518324728785912\n",
      "0.15140092071025185\n",
      "0.15096554012600313\n",
      "0.15052662034491507\n",
      "0.15009162515156685\n",
      "0.14966198776250716\n",
      "0.14923225576951182\n",
      "0.148802348923667\n",
      "0.14837219506510296\n",
      "0.14794172932676752\n",
      "0.14751089341639023\n",
      "0.14707963496896814\n",
      "0.1466479069628527\n",
      "0.14621566719320195\n",
      "0.1457828777971626\n",
      "0.14534950482571252\n",
      "0.1449155178575775\n",
      "0.14448088965109646\n",
      "0.14404559583030857\n",
      "0.14360961460190116\n",
      "0.14317292649998986\n",
      "0.14274090307826948\n",
      "0.1423051311880234\n",
      "0.14187043963697762\n",
      "0.14144735181077858\n",
      "0.14102662182667838\n",
      "0.14060474216143648\n",
      "0.1401818943015408\n",
      "0.13975808717028226\n",
      "0.13933694187615908\n",
      "0.13891248715962237\n",
      "0.13848650253929418\n",
      "0.1380621163973288\n",
      "0.13763436615941638\n",
      "0.13720527209886518\n",
      "0.1367748806806144\n",
      "0.1363432340329903\n",
      "0.1359103703663117\n",
      "0.13547632435105728\n",
      "0.1350539492534159\n",
      "0.1346417574878182\n",
      "0.13423347265801971\n",
      "0.13382590704606578\n",
      "0.13341891301459635\n",
      "0.13301235756991567\n",
      "0.13260612092363022\n",
      "0.13220009519538084\n",
      "0.13179418324283754\n",
      "0.13138829760648885\n",
      "0.13098235955796844\n",
      "0.1305766248164682\n",
      "0.13017075703168024\n",
      "0.12976467737706845\n",
      "0.1293583312307563\n",
      "0.12895166947140801\n",
      "0.1285446479371638\n",
      "0.12813674592553037\n",
      "0.12772811309578824\n",
      "0.12731893290250532\n",
      "0.1269091844353795\n",
      "0.12649884896568875\n",
      "0.1260879097313944\n",
      "0.12567635174333106\n",
      "0.12526416161041798\n",
      "0.12485132738202596\n",
      "0.12443783840581717\n",
      "0.12402368519954231\n",
      "0.12360885933542558\n",
      "0.12319335333590305\n",
      "0.12277716057960006\n",
      "0.12236027521654587\n",
      "0.12194269209171614\n",
      "0.12151223570017157\n",
      "0.12107028318240755\n",
      "0.12062336345357949\n",
      "0.12017189226304255\n",
      "0.11971624430834996\n",
      "0.11925675729874254\n",
      "0.11879373561643362\n",
      "0.11832745361549193\n",
      "0.1178411761170172\n",
      "0.1173472947328568\n",
      "0.11684795929420565\n",
      "0.1163436349838594\n",
      "0.11583474089069275\n",
      "0.11532165458527784\n",
      "0.11480471624119132\n",
      "0.11428423234713092\n",
      "0.1137604790504815\n",
      "0.11323370516893147\n",
      "0.11270413490310564\n",
      "0.11217197027990285\n",
      "0.11163739335328145\n",
      "0.11110056818657434\n",
      "0.11056164263802808\n",
      "0.11002074996910165\n",
      "0.10947801029312312\n",
      "0.10893353188015341\n",
      "0.1083884078498575\n",
      "0.10784245863810973\n",
      "0.10729518737968852\n",
      "0.1067466504961746\n",
      "0.10619689889286303\n",
      "0.10571712202034396\n",
      "0.10522938498410422\n",
      "0.10473996910320531\n",
      "0.10421276137513348\n",
      "0.10364744206510618\n",
      "0.10316914309587993\n",
      "0.1026876747267184\n",
      "0.10220328216208314\n",
      "0.10171802995668913\n",
      "0.10123074176808672\n",
      "0.10074106017780089\n",
      "0.10027684694068542\n",
      "0.09980132706659953\n",
      "0.09937727552831362\n",
      "0.09897478825028197\n",
      "0.09855773794390585\n",
      "0.09814284942985597\n",
      "0.0977233615753585\n",
      "0.09729917355920423\n",
      "0.0969330388711443\n",
      "0.0965619266217774\n",
      "0.09618554362497203\n",
      "0.09578610003177317\n",
      "0.09536868513445144\n",
      "0.0950210095332121\n",
      "0.09466933105538496\n",
      "0.0943059187128001\n",
      "0.09393185985054829\n",
      "0.09354813480892384\n",
      "0.09315562745799923\n",
      "0.09278609873157523\n",
      "0.09243016751039154\n",
      "0.09204579007126534\n",
      "0.09165771912181786\n",
      "0.09129506053002835\n",
      "0.09092615370855982\n",
      "0.09054540693029137\n",
      "0.09018675255996016\n",
      "0.08982288015342633\n",
      "0.08943348369519778\n",
      "0.08913180801030965\n",
      "0.08874815385606709\n",
      "0.08837037458439391\n",
      "0.08801214276600075\n",
      "0.08767041595701605\n",
      "0.08730153782065109\n",
      "0.08691605476772611\n",
      "0.08655641660807953\n",
      "0.08618619311728395\n",
      "0.08583742433705625\n",
      "0.08547009222009022\n",
      "0.08508535457764331\n",
      "0.08471683490189198\n",
      "0.08435418593478577\n",
      "0.08397509819038274\n",
      "0.08361455693592137\n",
      "0.08324526200455507\n",
      "0.08285600352591385\n",
      "0.08248413569409213\n",
      "0.0821070896262212\n",
      "0.0817061136590419\n",
      "0.08132511298241392\n",
      "0.08095240141522868\n",
      "0.08055728076799562\n",
      "0.08025843941486636\n",
      "0.07986051060840663\n",
      "0.07943505267181296\n",
      "0.07908073215072382\n",
      "0.07871780085052314\n",
      "0.07832268180504785\n",
      "0.0779456397442807\n",
      "0.0775811039969813\n",
      "0.07720577350009926\n",
      "0.07681355931395599\n",
      "0.07648020755517579\n",
      "0.07613566017701494\n",
      "0.07576838628648293\n",
      "0.07538056562725023\n",
      "0.07497416252496303\n",
      "0.07464895007513353\n",
      "0.07430475070487709\n",
      "0.07393445494605214\n",
      "0.0735798660893912\n",
      "0.07313149838344672\n",
      "0.07281688475929486\n",
      "0.07250286858240954\n",
      "0.0721623925085882\n",
      "0.07179800781302983\n",
      "0.07141201344846612\n",
      "0.07101639701026752\n",
      "0.07061297713571685\n"
     ]
    }
   ],
   "source": [
    "tree = generate_random_tree(pset, min_=1, max_=3)\n",
    "print(tree)\n",
    "x0 = tree_to_nodes_matrix(tree, pset, list(prims.keys()), n_nodes = max_nodes)\n",
    "x = optimize_tree(x0.ravel(), 1e-3, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1793ea46-01f6-421d-a581-2c81b4f1f960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1314, 0.1313, 0.3365, 0.1336, 0.1311, 0.1361],\n",
       "        [0.1329, 0.1160, 0.1198, 0.3806, 0.1219, 0.1288],\n",
       "        [0.1312, 0.3544, 0.1196, 0.1363, 0.1009, 0.1576],\n",
       "        [0.1135, 0.1486, 0.1131, 0.1647, 0.1275, 0.3326],\n",
       "        [0.0993, 0.1305, 0.1279, 0.1368, 0.1132, 0.3923],\n",
       "        [0.1342, 0.3657, 0.1296, 0.1325, 0.1303, 0.1078],\n",
       "        [0.1327, 0.1399, 0.1192, 0.1238, 0.1399, 0.3445],\n",
       "        [0.1351, 0.1207, 0.1461, 0.1338, 0.1218, 0.3425],\n",
       "        [0.1061, 0.1221, 0.1225, 0.3979, 0.1262, 0.1252],\n",
       "        [0.1180, 0.1378, 0.3576, 0.1382, 0.1202, 0.1282],\n",
       "        [0.1256, 0.1240, 0.1022, 0.1641, 0.1413, 0.3427],\n",
       "        [0.1139, 0.1126, 0.1165, 0.1391, 0.1221, 0.3958],\n",
       "        [0.1214, 0.1261, 0.1536, 0.3167, 0.1461, 0.1362],\n",
       "        [0.1134, 0.1255, 0.1239, 0.1462, 0.1511, 0.3398],\n",
       "        [0.1356, 0.1220, 0.1268, 0.1394, 0.1589, 0.3172]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = torch.nn.Softmax(dim=1)\n",
    "with torch.no_grad():\n",
    "    x_reshaped = torch.reshape(x, (max_nodes, n_prims))\n",
    "    x = sm(x_reshaped)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88672cac-f4cf-4010-9943-1e448f3a02f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['add', 'sub', 'mul', 'protectedDiv', 'cos', 'x']\n"
     ]
    }
   ],
   "source": [
    "print(list(prims.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae791fb6-7422-4a16-a75f-41ad9f2faad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
